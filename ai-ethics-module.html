<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>The Ethical Algorithm — AI Ethics Module</title>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link href="https://fonts.googleapis.com/css2?family=Playfair+Display:ital,wght@0,700;0,900;1,700&family=DM+Sans:wght@300;400;500&family=DM+Mono:wght@400;500&display=swap" rel="stylesheet">
<style>
*,*::before,*::after{box-sizing:border-box;margin:0;padding:0}
:root{
  --ink:#0d0d0d;--paper:#f5f0e8;--warm:#faf8f4;
  --red:#c0392b;--amber:#d97706;--teal:#0d6e6e;
  --grey:#6b6b6b;--lgrey:#e8e4dc;
  --dark:#111827;--mid:#1f2937;
  --hi:#fef3c7;--cpbg:#0d1117;
}
html{scroll-behavior:smooth}
body{font-family:'DM Sans',sans-serif;background:var(--paper);color:var(--ink);line-height:1.7;overflow-x:hidden}

/* PROGRESS */
#progress-bar{position:fixed;top:0;left:0;right:0;height:3px;background:rgba(0,0,0,0.1);z-index:1000}
#progress-fill{height:100%;background:var(--red);width:0%;transition:width 0.2s}

/* SIDEBAR */
#sidebar{position:fixed;left:0;top:0;bottom:0;width:220px;background:var(--ink);color:var(--paper);padding:40px 0;z-index:100;display:flex;flex-direction:column;transition:transform 0.3s}
#sidebar.hidden{transform:translateX(-220px)}
.sb-logo{padding:0 24px 32px;font-family:'Playfair Display',serif;font-size:13px;line-height:1.4;border-bottom:1px solid rgba(255,255,255,0.1);margin-bottom:16px}
.sb-logo strong{display:block;font-size:11px;letter-spacing:0.12em;text-transform:uppercase;color:var(--red);margin-bottom:4px}
.nav-item{padding:8px 24px;font-size:12px;cursor:pointer;color:rgba(255,255,255,0.5);border-left:2px solid transparent;transition:all 0.2s;line-height:1.4}
.nav-item:hover{color:rgba(255,255,255,0.85)}
.nav-item.active{color:white;border-left-color:var(--red)}
.nav-num{font-family:'DM Mono',monospace;font-size:10px;color:var(--red);display:block;margin-bottom:1px}
#sb-toggle{position:fixed;left:220px;top:50%;transform:translateY(-50%);width:20px;height:48px;background:var(--ink);z-index:101;border:none;cursor:pointer;color:white;font-size:12px;border-radius:0 4px 4px 0;transition:left 0.3s;display:flex;align-items:center;justify-content:center}
#sb-toggle.hidden{left:0}

/* MAIN */
#main{margin-left:220px;transition:margin-left 0.3s}
#main.full{margin-left:0}

/* SECTIONS */
.section{min-height:100vh;padding:80px 60px 80px 80px;max-width:860px;position:relative}
.section-dark{background:var(--dark);color:var(--warm);max-width:none;padding:80px 60px 80px 80px}
.section-mid{background:var(--mid);color:var(--warm);max-width:none;padding:80px 60px 80px 80px}
.section-paper{background:#fdf8f0}

/* HERO */
.hero{min-height:100vh;display:flex;flex-direction:column;justify-content:center;background:var(--ink);color:var(--paper);padding:80px;position:relative;overflow:hidden}
.hero::before{content:'';position:absolute;top:0;left:0;right:0;bottom:0;background:repeating-linear-gradient(0deg,transparent,transparent 60px,rgba(255,255,255,0.02) 60px,rgba(255,255,255,0.02) 61px);pointer-events:none}
.hero-eyebrow{font-family:'DM Mono',monospace;font-size:11px;letter-spacing:0.2em;text-transform:uppercase;color:var(--red);margin-bottom:32px}
.hero-q{font-family:'Playfair Display',serif;font-size:clamp(26px,4vw,50px);line-height:1.2;font-style:italic;max-width:720px;margin-bottom:48px;color:var(--paper)}
.hero-sub{font-size:15px;max-width:560px;line-height:1.8;color:rgba(245,240,232,0.7);margin-bottom:40px}
.hero-cta{display:inline-flex;align-items:center;gap:12px;font-family:'DM Mono',monospace;font-size:12px;letter-spacing:0.15em;text-transform:uppercase;color:var(--red);cursor:pointer;border:none;background:none;padding:0;transition:gap 0.2s}
.hero-cta:hover{gap:20px}
.cta-line{width:40px;height:1px;background:var(--red)}

/* TIMELINE */
.timeline{display:flex;gap:0;margin:48px 0;border-top:1px solid rgba(255,255,255,0.15);padding-top:32px}
.tl-item{flex:1;padding:0 20px 0 0;border-right:1px solid rgba(255,255,255,0.1);margin-right:20px}
.tl-item:last-child{border-right:none;margin-right:0}
.tl-era{font-family:'DM Mono',monospace;font-size:10px;color:var(--red);letter-spacing:0.1em;margin-bottom:8px}
.tl-title{font-family:'Playfair Display',serif;font-size:15px;margin-bottom:6px;color:var(--paper)}
.tl-desc{font-size:12px;color:rgba(245,240,232,0.5);line-height:1.5}
.tl-now{background:rgba(192,57,43,0.15);border-radius:4px;padding:12px;border:1px solid rgba(192,57,43,0.3)}

/* LABELS & TITLES */
.sec-label{font-family:'DM Mono',monospace;font-size:10px;letter-spacing:0.2em;text-transform:uppercase;color:var(--red);margin-bottom:16px;display:block}
.sec-title{font-family:'Playfair Display',serif;font-size:clamp(24px,3.5vw,42px);line-height:1.15;margin-bottom:20px;font-weight:700}
.sec-intro{font-size:15px;color:var(--grey);line-height:1.8;max-width:620px;margin-bottom:48px;border-left:3px solid var(--red);padding-left:20px}
.section-dark .sec-intro,.section-mid .sec-intro{color:rgba(255,255,255,0.6)}

/* CARDS */
.card-grid{display:grid;grid-template-columns:1fr 1fr;gap:20px;margin:32px 0}
.card{border:1px solid var(--lgrey);padding:24px;background:var(--warm);border-radius:2px;transition:border-color 0.2s,box-shadow 0.2s;margin-bottom:0}
.card:hover{border-color:var(--red);box-shadow:4px 4px 0 var(--red)}
.card-n{font-family:'DM Mono',monospace;font-size:10px;color:var(--red);letter-spacing:0.1em;margin-bottom:10px}
.card-t{font-family:'Playfair Display',serif;font-size:17px;margin-bottom:10px;font-weight:700}
.card-b{font-size:13px;color:var(--grey);line-height:1.7}
.card-ex{margin-top:12px;padding:10px 12px;background:var(--hi);border-left:3px solid var(--amber);font-size:12px;line-height:1.6}
.card-ex strong{color:var(--amber);font-size:10px;letter-spacing:0.1em;text-transform:uppercase;display:block;margin-bottom:3px}

/* DARK CARDS */
.dcard{border:1px solid rgba(255,255,255,0.1);padding:24px;background:rgba(255,255,255,0.04);border-radius:2px;margin-bottom:20px;transition:border-color 0.2s}
.dcard:hover{border-color:rgba(192,57,43,0.5)}
.dcard .card-n{color:var(--red)}
.dcard .card-t{color:var(--warm)}
.dcard .card-b{color:rgba(255,255,255,0.55)}
.dcard .card-ex{background:rgba(217,119,6,0.1);border-left-color:var(--amber);color:rgba(255,255,255,0.7)}

/* CALLOUT */
.callout{background:var(--ink);color:var(--paper);padding:24px 28px;margin:32px 0;border-radius:2px;font-family:'Playfair Display',serif;font-size:17px;font-style:italic;line-height:1.5;position:relative}
.callout::before{content:'"';position:absolute;top:8px;left:16px;font-size:60px;color:var(--red);line-height:1;font-family:'Playfair Display',serif;opacity:0.4}
.callout-text{padding-left:28px}
.dcallout{background:rgba(255,255,255,0.05);border:1px solid rgba(255,255,255,0.1);padding:20px 24px;margin:24px 0;font-size:14px;color:rgba(255,255,255,0.65);line-height:1.8;border-left:3px solid var(--teal)}
.dcallout.amber{border-left-color:var(--amber)}
.dcallout.red{border-left-color:var(--red)}

/* PIPELINE */
.pipeline{display:flex;flex-wrap:wrap;gap:4px;margin:24px 0;align-items:center}
.pipe-step{padding:8px 14px;border:1px solid rgba(255,255,255,0.15);font-family:'DM Mono',monospace;font-size:11px;color:rgba(255,255,255,0.7);border-radius:2px;background:rgba(255,255,255,0.05)}
.pipe-arrow{color:rgba(192,57,43,0.7);font-size:16px}

/* CHECKPOINTS */
.checkpoint{margin:48px -60px 48px -80px;padding:48px 80px;background:var(--cpbg);border-top:2px solid var(--red);border-bottom:2px solid var(--red);color:var(--warm);position:relative}
.checkpoint::before{content:'CHECKPOINT';position:absolute;top:-12px;left:80px;background:var(--red);color:white;font-family:'DM Mono',monospace;font-size:10px;letter-spacing:0.2em;padding:3px 12px}
.cp-id{font-family:'DM Mono',monospace;font-size:11px;color:rgba(192,57,43,0.7);margin-bottom:16px;letter-spacing:0.1em}
.cp-type{font-size:12px;color:rgba(255,255,255,0.4);margin-bottom:20px;font-style:italic}
.cp-scenario{background:rgba(255,255,255,0.04);border-left:3px solid rgba(192,57,43,0.5);padding:16px 20px;margin-bottom:24px;font-size:14px;color:rgba(255,255,255,0.8);line-height:1.8;border-radius:0 2px 2px 0}
.cp-qs{list-style:none}
.cp-q{padding:16px 0;border-bottom:1px solid rgba(255,255,255,0.06);font-size:14px;color:rgba(255,255,255,0.75);line-height:1.7}
.cp-q:last-child{border-bottom:none}
.q-lbl{font-family:'DM Mono',monospace;font-size:10px;color:var(--red);letter-spacing:0.1em;margin-bottom:6px;display:block}
.cp-note{margin-top:20px;padding:12px 16px;border:1px solid rgba(255,255,255,0.08);font-size:12px;font-style:italic;color:rgba(255,255,255,0.4);line-height:1.6}
.cp-input{width:100%;background:rgba(255,255,255,0.05);border:1px solid rgba(255,255,255,0.15);color:white;padding:12px 16px;font-family:'DM Sans',sans-serif;font-size:13px;border-radius:2px;resize:vertical;min-height:72px;margin-top:10px;line-height:1.6}
.cp-input:focus{outline:none;border-color:var(--red)}
.cp-input::placeholder{color:rgba(255,255,255,0.25)}

/* FRAMEWORKS */
.fw-tabs{display:flex;gap:8px;flex-wrap:wrap;margin-bottom:32px}
.fw-tab{padding:8px 16px;border:1px solid rgba(255,255,255,0.2);font-family:'DM Mono',monospace;font-size:11px;cursor:pointer;border-radius:2px;background:transparent;color:rgba(255,255,255,0.5);transition:all 0.2s;letter-spacing:0.05em}
.fw-tab:hover{color:white;border-color:rgba(255,255,255,0.5)}
.fw-tab.active{background:var(--red);border-color:var(--red);color:white}
.fw-panel{display:none}
.fw-panel.active{display:block;animation:fadeIn 0.3s ease}
.fw-principle{font-family:'Playfair Display',serif;font-size:19px;font-style:italic;color:white;margin-bottom:20px;line-height:1.4;border-left:3px solid var(--red);padding-left:20px}
.fw-grid{display:grid;grid-template-columns:1fr 1fr;gap:20px;margin:20px 0}
.fw-box{padding:16px 20px;border-radius:2px}
.fw-str{background:rgba(13,110,110,0.15);border:1px solid rgba(13,110,110,0.3)}
.fw-lim{background:rgba(192,57,43,0.1);border:1px solid rgba(192,57,43,0.2)}
.fw-blbl{font-family:'DM Mono',monospace;font-size:10px;letter-spacing:0.1em;text-transform:uppercase;margin-bottom:8px}
.fw-str .fw-blbl{color:#4ade80}
.fw-lim .fw-blbl{color:var(--red)}
.fw-btext{font-size:13px;color:rgba(255,255,255,0.7);line-height:1.6}

/* FRAMEWORK COMPARISON */
.fcomp-case{background:rgba(255,255,255,0.04);padding:20px;border-radius:2px;border:1px solid rgba(255,255,255,0.08);margin-bottom:24px;font-size:14px;color:rgba(255,255,255,0.75);line-height:1.7}
.fcomp-verdict{background:rgba(255,255,255,0.04);padding:20px;border-radius:2px;border-left:3px solid var(--red);font-size:14px;color:rgba(255,255,255,0.75);line-height:1.7;animation:fadeIn 0.25s ease}
.fcomp-lbl{font-family:'DM Mono',monospace;font-size:10px;color:var(--red);letter-spacing:0.1em;margin-bottom:10px;display:block}

/* SURVEILLANCE */
.surv-row{display:grid;grid-template-columns:1fr auto;gap:16px;padding:12px 0;border-bottom:1px solid rgba(255,255,255,0.06);align-items:start}
.surv-txt{font-size:13px;color:rgba(255,255,255,0.7);line-height:1.5}
.surv-btns{display:flex;gap:4px;flex-shrink:0}
.surv-btn{padding:4px 10px;font-size:10px;cursor:pointer;border:1px solid rgba(255,255,255,0.2);background:transparent;color:rgba(255,255,255,0.5);border-radius:2px;font-family:'DM Mono',monospace;letter-spacing:0.05em;transition:all 0.15s}
.surv-btn:hover{border-color:white;color:white}
.surv-btn.ok{background:rgba(52,211,153,0.2);border-color:#34d399;color:#34d399}
.surv-btn.no{background:rgba(192,57,43,0.2);border-color:var(--red);color:var(--red)}
.surv-btn.cond{background:rgba(251,191,36,0.15);border-color:#fbbf24;color:#fbbf24}

/* HEADLINES / EUAI */
.hl-row,.euai-row{display:grid;grid-template-columns:1fr auto;gap:16px;padding:12px 0;border-bottom:1px solid rgba(255,255,255,0.06);align-items:center}
.hl-txt{font-size:13px;color:rgba(255,255,255,0.75);line-height:1.5;font-style:italic}
.euai-txt{font-size:13px;color:rgba(255,255,255,0.75);line-height:1.5}
.cat-sel,.euai-sel{min-width:150px;padding:6px 10px;background:rgba(255,255,255,0.05);border:1px solid rgba(255,255,255,0.2);color:rgba(255,255,255,0.7);font-size:11px;border-radius:2px;font-family:'DM Mono',monospace}
.cat-sel:focus,.euai-sel:focus{outline:none;border-color:var(--red)}

/* CASES */
.case-hdr{display:flex;align-items:baseline;gap:16px;margin-bottom:20px;padding-bottom:16px;border-bottom:1px solid rgba(255,255,255,0.1)}
.case-letter{font-family:'Playfair Display',serif;font-size:60px;line-height:1;color:rgba(192,57,43,0.3);font-weight:900}
.case-t{font-family:'Playfair Display',serif;font-size:22px;color:white;margin-bottom:4px}
.case-yr{font-family:'DM Mono',monospace;font-size:11px;color:var(--red);letter-spacing:0.1em}
.case-body{font-size:14px;color:rgba(255,255,255,0.65);line-height:1.8;margin-bottom:24px}
.verdict{padding:12px 16px;margin-bottom:8px;border-left:3px solid;border-radius:0 2px 2px 0;font-size:13px;line-height:1.6}
.v-c{border-color:#60a5fa;background:rgba(96,165,250,0.08);color:rgba(255,255,255,0.7)}
.v-d{border-color:#a78bfa;background:rgba(167,139,250,0.08);color:rgba(255,255,255,0.7)}
.v-f{border-color:#34d399;background:rgba(52,211,153,0.08);color:rgba(255,255,255,0.7)}
.v-v{border-color:#fbbf24;background:rgba(251,191,36,0.08);color:rgba(255,255,255,0.7)}
.v-r{border-color:#f472b6;background:rgba(244,114,182,0.08);color:rgba(255,255,255,0.7)}
.v-lbl{font-family:'DM Mono',monospace;font-size:10px;letter-spacing:0.1em;opacity:0.7;margin-bottom:4px;display:block}
.acc-chain{background:rgba(0,0,0,0.3);padding:20px;margin:20px 0;border-radius:2px;border:1px solid rgba(255,255,255,0.08)}
.acc-lbl{font-family:'DM Mono',monospace;font-size:10px;letter-spacing:0.15em;color:var(--red);margin-bottom:12px}
.acc-items{display:flex;flex-wrap:wrap;gap:8px;align-items:center}
.acc-item{padding:6px 12px;border:1px solid rgba(255,255,255,0.15);font-size:11px;color:rgba(255,255,255,0.7);border-radius:2px;white-space:pre-line;line-height:1.4}
.acc-arr{color:var(--red);font-size:14px}
.never-asked{margin-top:20px;padding:16px 20px;background:rgba(192,57,43,0.1);border:1px solid rgba(192,57,43,0.3);border-radius:2px}
.na-lbl{font-family:'DM Mono',monospace;font-size:10px;color:var(--red);letter-spacing:0.1em;margin-bottom:8px}
.na-q{font-family:'Playfair Display',serif;font-style:italic;font-size:15px;color:rgba(255,255,255,0.8);line-height:1.5}

/* TRANSITION */
.transition{min-height:60vh;display:flex;align-items:center;justify-content:center;background:var(--ink);padding:80px;position:relative;overflow:hidden}
.transition::after{content:'';position:absolute;top:0;left:0;right:0;bottom:0;background:radial-gradient(ellipse at 30% 50%,rgba(192,57,43,0.08) 0%,transparent 60%);pointer-events:none}
.trans-text{font-family:'Playfair Display',serif;font-size:clamp(20px,3vw,36px);font-style:italic;color:var(--paper);text-align:center;max-width:700px;line-height:1.5;position:relative;z-index:1}
.trans-line{width:60px;height:2px;background:var(--red);margin:24px auto}

/* AUDIT */
.audit-cluster{margin-bottom:32px}
.audit-ctitle{font-family:'DM Mono',monospace;font-size:11px;letter-spacing:0.15em;text-transform:uppercase;color:var(--amber);margin-bottom:16px;padding-bottom:8px;border-bottom:1px solid rgba(217,119,6,0.3)}
.audit-q{display:flex;gap:16px;padding:16px 0;border-bottom:1px solid rgba(255,255,255,0.06);align-items:flex-start}
.audit-num{font-family:'DM Mono',monospace;font-size:20px;color:rgba(192,57,43,0.3);line-height:1;flex-shrink:0;width:28px}
.audit-txt{font-size:14px;color:rgba(255,255,255,0.75);line-height:1.7}

/* REPORT */
.report-sec{padding:20px 24px;margin-bottom:12px;border-left:3px solid;border-radius:0 2px 2px 0;background:rgba(255,255,255,0.03)}
.report-sec:nth-child(1){border-color:#60a5fa}
.report-sec:nth-child(2){border-color:#a78bfa}
.report-sec:nth-child(3){border-color:#34d399}
.report-sec:nth-child(4){border-color:#fbbf24}
.rep-title{font-weight:600;color:white;font-size:14px;margin-bottom:6px}
.rep-wc{font-family:'DM Mono',monospace;font-size:10px;color:var(--red);float:right}
.rep-desc{font-size:13px;color:rgba(255,255,255,0.55);line-height:1.7}
.rep-test{font-size:12px;font-style:italic;color:rgba(255,255,255,0.35);margin-top:8px}

/* EXIT */
.exit-q{padding:28px 0;border-bottom:1px solid rgba(255,255,255,0.08)}
.exit-n{font-family:'Playfair Display',serif;font-size:48px;font-weight:900;color:rgba(192,57,43,0.15);line-height:1;margin-bottom:12px}
.exit-t{font-size:16px;color:white;line-height:1.7;margin-bottom:10px}
.exit-h{font-size:13px;color:rgba(255,255,255,0.35);font-style:italic;line-height:1.5}
.final-commit{margin-top:48px;padding:32px;background:rgba(192,57,43,0.1);border:1px solid rgba(192,57,43,0.3);border-radius:2px}
.fc-lbl{font-family:'DM Mono',monospace;font-size:11px;letter-spacing:0.15em;color:var(--red);margin-bottom:16px}
.fc-prompt{font-family:'Playfair Display',serif;font-size:18px;color:white;margin-bottom:20px;line-height:1.5}
.commit-input{width:100%;background:rgba(0,0,0,0.3);border:1px solid rgba(192,57,43,0.4);color:white;padding:16px 20px;font-family:'Playfair Display',serif;font-size:15px;border-radius:2px;resize:none;height:100px;line-height:1.6;font-style:italic}
.commit-input:focus{outline:none;border-color:var(--red)}
#commit-confirm{display:none;margin-top:16px;padding:12px 16px;background:rgba(52,211,153,0.1);border:1px solid rgba(52,211,153,0.3);border-radius:2px;font-size:12px;color:#34d399;font-family:'DM Mono',monospace;letter-spacing:0.05em}

@keyframes fadeIn{from{opacity:0;transform:translateY(4px)}to{opacity:1;transform:translateY(0)}}

@media(max-width:768px){
  #sidebar{transform:translateX(-220px)}
  #main{margin-left:0}
  .section,.section-dark,.section-mid{padding:60px 24px}
  .section-paper{padding:60px 24px}
  .hero{padding:60px 24px}
  .checkpoint{margin:32px -24px;padding:32px 24px}
  .checkpoint::before{left:24px}
  .card-grid,.fw-grid{grid-template-columns:1fr}
  .timeline{flex-direction:column;gap:16px}
  .tl-item{border-right:none;border-bottom:1px solid rgba(255,255,255,0.1);padding-bottom:16px;margin-right:0}
  .surv-row,.hl-row,.euai-row{grid-template-columns:1fr}
  .surv-btns{margin-top:8px}
}
</style>
</head>
<body>

<div id="progress-bar"><div id="progress-fill"></div></div>

<nav id="sidebar">
  <div class="sb-logo"><strong>IBM · Week 3</strong>The Ethical Algorithm</div>
  <div class="nav-item active" onclick="scrollTo('s0')"><span class="nav-num">00</span>The Hook</div>
  <div class="nav-item" onclick="scrollTo('s1a')"><span class="nav-num">01</span>Business Impact</div>
  <div class="nav-item" onclick="scrollTo('s1b')"><span class="nav-num">02</span>Societal Impact</div>
  <div class="nav-item" onclick="scrollTo('s2')"><span class="nav-num">03</span>Ethical Issues</div>
  <div class="nav-item" onclick="scrollTo('s3')"><span class="nav-num">04</span>Frameworks</div>
  <div class="nav-item" onclick="scrollTo('s4')"><span class="nav-num">05</span>Case Studies</div>
  <div class="nav-item" onclick="scrollTo('s5')"><span class="nav-num">06</span>Your Audit</div>
  <div class="nav-item" onclick="scrollTo('s6')"><span class="nav-num">07</span>Exit Check</div>
</nav>
<button id="sb-toggle" onclick="toggleSidebar()">&#8249;</button>

<div id="main">

<!-- ═══════════════════════════════════════════
     SECTION 0 — HERO / HOOK
═══════════════════════════════════════════ -->
<section id="s0" class="hero">
  <div class="hero-eyebrow">Impact of New Technologies on Business &amp; Society · Ethical Implications of AI &amp; ML</div>
  <h1 class="hero-q">"If an algorithm denied your loan, your job application, or your medical diagnosis — and no human reviewed it — who would you call?"</h1>
  <p class="hero-sub">New technologies have fundamentally altered how businesses operate and how societies function. This is not a prediction about the future. It is a description of the present. This module asks you to stop treating that as background noise and start treating it as a design problem with real stakes.</p>
  <button class="hero-cta" onclick="document.getElementById('s0-timeline').scrollIntoView({behavior:'smooth'})">Begin the Journey <span class="cta-line"></span> →</button>

  <div id="s0-timeline" class="timeline" style="margin-top:80px">
    <div class="tl-item">
      <div class="tl-era">Industry 1.0</div>
      <div class="tl-title">Steam Power</div>
      <div class="tl-desc">1760s — Mechanisation</div>
    </div>
    <div class="tl-item">
      <div class="tl-era">Industry 2.0</div>
      <div class="tl-title">Electricity</div>
      <div class="tl-desc">1870s — Assembly lines</div>
    </div>
    <div class="tl-item">
      <div class="tl-era">Industry 3.0</div>
      <div class="tl-title">Computing</div>
      <div class="tl-desc">1960s — Automation</div>
    </div>
    <div class="tl-item tl-now">
      <div class="tl-era">Industry 4.0</div>
      <div class="tl-title">AI &amp; Machine Learning</div>
      <div class="tl-desc">Now — Interconnected systems</div>
    </div>
  </div>

  <div class="callout" style="margin-top:48px">
    <div class="callout-text">Each industrial revolution created enormous wealth — and enormous disruption. The people who shaped the ethical and regulatory responses determined who benefited and who was left behind. We are in that window right now for AI.</div>
  </div>

  <div class="checkpoint">
    <div class="cp-id">0.1 — Opening Scenario: Is This Fair?</div>
    <div class="cp-type">Type: Judgment call — commit to a position before theory is introduced</div>
    <div class="cp-scenario"><strong>Scenario:</strong> A major European bank uses an AI system to process mortgage applications in under three seconds. No human reviewer is involved. Approval rates have improved and costs are down 40%.<br><br>A customer receives a rejection: <em>"Your application did not meet our criteria."</em> No further explanation. The customer is a 34-year-old nurse with a clean credit history who has never missed a bill payment.</div>
    <ul class="cp-qs">
      <li class="cp-q"><span class="q-lbl">QUESTION 1</span>Do you think this system is being used ethically? (Yes / No / It depends) — briefly state why.<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 2</span>What information would you need to make a confident judgment?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 3</span>Who, if anyone, should the nurse be able to appeal to?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
    </ul>
    <div class="cp-note">This checkpoint has no correct answer yet. You will return to it with better tools in Section 04 — Frameworks.</div>
  </div>
</section>

<!-- ═══════════════════════════════════════════
     SECTION 1A — BUSINESS IMPACT
═══════════════════════════════════════════ -->
<section id="s1a" class="section">
  <span class="sec-label">Section 01 — Business</span>
  <h2 class="sec-title">How AI Is Transforming Business</h2>
  <p class="sec-intro">AI and ML are not being adopted because companies are reckless. They are being adopted because they work. Understanding what "working" means — and for whom — is where the ethical analysis begins.</p>

  <div class="card-grid">
    <div class="card">
      <div class="card-n">01 / 04</div>
      <div class="card-t">Automation &amp; Efficiency</div>
      <div class="card-b">AI automates repetitive, rule-based tasks — increasing throughput and reducing human error in processes that previously required significant manual labour.</div>
      <div class="card-ex"><strong>Real Example</strong>Amazon's 750,000+ Kiva warehouse robots handle item retrieval and transport, enabling order volumes impossible at human speed — while restructuring human roles from physical tasks to machine supervision.</div>
    </div>
    <div class="card">
      <div class="card-n">02 / 04</div>
      <div class="card-t">Customer Experience</div>
      <div class="card-b">AI-driven recommendation engines, chatbots, and personalised marketing have changed how businesses interact with customers — making interactions faster, more tailored, and always-on.</div>
      <div class="card-ex"><strong>Real Example</strong>Netflix's recommendation algorithm prevents ~$1B in annual customer churn. Without it, Netflix estimates 80% of watched content would never be discovered through browsing alone.</div>
    </div>
    <div class="card">
      <div class="card-n">03 / 04</div>
      <div class="card-t">Data-Driven Decision Making</div>
      <div class="card-b">Big data analytics now drives decisions across marketing, logistics, finance, and HR at a speed and scale human analysts cannot match.</div>
      <div class="card-ex"><strong>Real Example</strong>In financial services, predictive risk models assess loan default probability across hundreds of variables — enabling faster credit assessment, but also encoding historical biases at scale. (Class example: BMCE Bank of Africa.)</div>
    </div>
    <div class="card">
      <div class="card-n">04 / 04</div>
      <div class="card-t">Globalisation &amp; Competition</div>
      <div class="card-b">Technology removes geographic barriers to market entry — but also removes the protection distance once provided for local businesses.</div>
      <div class="card-ex"><strong>Real Example</strong>A Belgian SME in retail competes against Amazon's pricing engine, which adjusts prices up to 2.5 million times per day. Competing through intuition alone is not viable.</div>
    </div>
  </div>

  <div class="checkpoint">
    <div class="cp-id">1A.1 — Quick Application: Automate or Not?</div>
    <div class="cp-type">Type: Pattern recognition — 60 seconds, applied to your own business case context</div>
    <ul class="cp-qs">
      <li class="cp-q"><span class="q-lbl">QUESTION 1</span>Think about the industry your current business case focuses on. Name one specific task that AI could automate today with existing technology.<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 2</span>Name one task in the same industry that AI could NOT automate — and explain why not.<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
    </ul>
    <div class="cp-note">The boundary between your two answers is where the most interesting ethical questions live.</div>
  </div>

  <div class="checkpoint">
    <div class="cp-id">1A.2 — Scenario: The Pitch</div>
    <div class="cp-type">Type: Role play — defend a position, then examine what you left out</div>
    <div class="cp-scenario"><strong>Scenario:</strong> You are the operations director at a mid-sized Belgian insurance company. Your CEO asks you to present the business case for replacing your 12-person claims processing team with an AI system that handles the same volume in real time at 15% of the current cost.</div>
    <ul class="cp-qs">
      <li class="cp-q"><span class="q-lbl">QUESTION 1</span>What are the three strongest arguments you would make <em>in favour</em> of adopting the system?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 2</span>What are the three strongest arguments <em>against</em> — and are any strong enough to change your recommendation?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 3</span>If you proceed, what obligations do you have to the 12 people whose roles are affected?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
    </ul>
    <div class="cp-note">Notice what you left out of your pitch. That is almost always where the ethical problem lives.</div>
  </div>
</section>

<!-- ═══════════════════════════════════════════
     SECTION 1B — SOCIETAL IMPACT
═══════════════════════════════════════════ -->
<section id="s1b" class="section section-paper">
  <span class="sec-label">Section 02 — Society</span>
  <h2 class="sec-title">How Technology Is Reshaping Society</h2>
  <p class="sec-intro" style="color:#555">When businesses adopt AI at scale, society absorbs the consequences. Not always the same society that captured the benefits.</p>

  <div class="card" style="margin-bottom:16px">
    <div class="card-n">01 / 06</div><div class="card-t">Job Displacement &amp; Creation</div>
    <div class="card-b">Automation eliminates middle-skill, predictable-income roles while creating jobs requiring higher qualifications or offering less stability. The distribution is deeply uneven.</div>
    <div class="card-ex"><strong>Real Example</strong>Gig platforms — Uber, Deliveroo — created flexible income for millions while stripping sick pay, pension, and employment contracts. Belgium's Court of Cassation (2021) ruled some Deliveroo riders were employees, not contractors — a landmark decision reflecting Europe-wide legal tension.</div>
  </div>
  <div class="card" style="margin-bottom:16px">
    <div class="card-n">02 / 06</div><div class="card-t">Data Privacy</div>
    <div class="card-b">The collection and monetisation of personal data has dramatically outpaced the legal frameworks designed to protect individuals. Most users have no meaningful understanding of what data is collected or how it is used.</div>
    <div class="card-ex"><strong>Real Example</strong>Cambridge Analytica (2018): 87M Facebook profiles harvested via a quiz app and used to build psychographic profiles for political micro-targeting — without users' knowledge. GDPR followed, but consent banners are still designed to make declining as inconvenient as possible.</div>
  </div>
  <div class="card" style="margin-bottom:16px">
    <div class="card-n">03 / 06</div><div class="card-t">The Digital Divide</div>
    <div class="card-b">Access to technology is not evenly distributed. The divide is self-reinforcing — those without digital access fall further behind in education, employment, and civic participation.</div>
    <div class="card-ex"><strong>Real Example</strong>During COVID-19 closures, a significant proportion of lower-income Belgian students lacked devices or reliable internet for remote learning. Globally, ~2.7 billion people have never used the internet.</div>
  </div>
  <div class="card" style="margin-bottom:16px">
    <div class="card-n">04 / 06</div><div class="card-t">Social Dynamics &amp; Misinformation</div>
    <div class="card-b">Platform algorithms optimise for engagement, which correlates with outrage and fear — causing algorithms to systematically amplify divisive content regardless of its accuracy.</div>
    <div class="card-ex"><strong>Real Example</strong>Meta's own internal research (leaked 2021 by Frances Haugen) showed Facebook's algorithm amplified misinformation because it drove higher engagement. Leadership declined recommended changes, citing growth metrics.</div>
  </div>
  <div class="card" style="margin-bottom:16px">
    <div class="card-n">05 / 06</div><div class="card-t">Healthcare — Promise and Peril</div>
    <div class="card-b">AI offers transformative diagnostic potential — but introduces bias when training data underrepresents certain populations, causing systems to perform systematically worse for those groups.</div>
    <div class="card-ex"><strong>Real Example</strong>A 2019 Science study found a US healthcare algorithm (affecting 200M people) systematically under-referred Black patients — using cost as a proxy for need, encoding historic access barriers. An NHS dermatology AI performed worse on darker skin tones.</div>
  </div>
  <div class="card" style="margin-bottom:32px">
    <div class="card-n">06 / 06</div><div class="card-t">Environmental Impact</div>
    <div class="card-b">Training large AI models requires enormous computational resources. The carbon footprint of AI infrastructure is significant and growing rapidly.</div>
    <div class="card-ex"><strong>Real Example</strong>Training GPT-3 emitted ~552 tonnes of CO₂ equivalent (Strubell et al.) — roughly the lifetime emissions of five average Americans, for a single training run. ESG reporting requirements mean this cost will increasingly appear on corporate balance sheets.</div>
  </div>

  <div class="checkpoint">
    <div class="cp-id">1B.1 — Perspective Shift: The Other Side of the Decision</div>
    <div class="cp-type">Type: Empathy exercise — step out of the manager's chair</div>
    <div class="cp-scenario"><strong>Scenario:</strong> You have worked as a data entry clerk at a logistics company for six years. You are good at your job. Your manager tells you that an AI system will take over your role in three months. You will be offered "retraining opportunities."</div>
    <ul class="cp-qs">
      <li class="cp-q"><span class="q-lbl">QUESTION 1</span>What are the first three questions you want answered — honestly?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 2</span>What would fair treatment from the company look like, beyond the legal minimum?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 3</span>Now switch back to the manager's chair. Does your answer to Question 2 change what you recommend to the CEO?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
    </ul>
    <div class="cp-note">The gap between your answers to Questions 2 and 3 is the space where corporate ethics either exists or does not.</div>
  </div>

  <div class="checkpoint">
    <div class="cp-id">1B.2 — Data Audit: Your Own Digital Footprint</div>
    <div class="cp-type">Type: Personal reflection — immediate, visceral application</div>
    <ul class="cp-qs">
      <li class="cp-q"><span class="q-lbl">QUESTION 1</span>Consider the last 48 hours: phone use, browsing, social media, navigation, streaming, purchases. Name five pieces of personal data almost certainly collected about you without you actively providing them.<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 2</span>For each one, name the company most likely holding that data. Do you know what they do with it?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 3</span>Under GDPR, you have the right to request all data a company holds about you. Have you ever done this? If not — why not?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
    </ul>
    <div class="cp-note">The answer to Question 3 tells you something important about the gap between legal rights and practical power.</div>
  </div>

  <div class="checkpoint">
    <div class="cp-id">1B.3 — Algorithm Audit: Your Own Feed</div>
    <div class="cp-type">Type: Critical observation — examine your own experience as evidence</div>
    <ul class="cp-qs">
      <li class="cp-q"><span class="q-lbl">QUESTION 1</span>Think about your social media use over the past week. Identify one piece of content you believe the algorithm recommended because it was likely to provoke a reaction — not because it was true or useful.<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 2</span>Did you share it, comment on it, or click on it? If yes — you fed the loop. How does that make you feel?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 3</span>If you were the product manager responsible for this algorithm, and you knew it amplified misinformation but was driving a 12% increase in daily active users — what would you do? What would most companies do?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
    </ul>
    <div class="cp-note">The gap between your answer and "what most companies do" is the size of the ethical problem.</div>
  </div>

  <div class="checkpoint">
    <div class="cp-id">1B.4 — The Triage Question: Which System Do You Audit First?</div>
    <div class="cp-type">Type: Prioritisation under constraint — surface your implicit ethical criteria</div>
    <div class="cp-scenario"><strong>Scenario:</strong> You are advising a European tech company that uses AI across five areas: customer personalisation, HR recruitment screening, predictive maintenance, content moderation, and supply chain optimisation. The company must conduct an independent ethical audit — but only has budget to audit <strong>two</strong> of the five systems this year.</div>
    <ul class="cp-qs">
      <li class="cp-q"><span class="q-lbl">QUESTION 1</span>Which two would you prioritise, and why?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 2</span>What criterion did you use to rank them — potential for harm, scale of impact, reversibility of decisions, or something else?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 3</span>Is the system you ranked last genuinely low-risk — or did you deprioritise it because it would be inconvenient to audit?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
    </ul>
    <div class="cp-note">Your prioritisation criteria reveal your implicit ethical framework — even before you have learned the frameworks by name.</div>
  </div>

  <div class="checkpoint">
    <div class="cp-id">1B.5 — Pattern Recognition: Name the Category</div>
    <div class="cp-type">Type: Classification exercise — consolidate learning across all six themes</div>
    <p style="color:rgba(255,255,255,0.7);font-size:14px;margin-bottom:16px;line-height:1.7">For each headline below, identify which societal impact category it primarily illustrates.<br>Categories: <strong>Job Displacement | Data Privacy | Digital Divide | Social Dynamics | Healthcare | Environmental Impact</strong></p>
    <div id="hl-rows">
      <div class="hl-row"><div class="hl-txt">"Spotify's algorithm is making it harder for independent artists to get heard."</div><select class="cat-sel"><option>— Select —</option><option>Job Displacement</option><option>Data Privacy</option><option>Digital Divide</option><option>Social Dynamics</option><option>Healthcare</option><option>Environmental Impact</option></select></div>
      <div class="hl-row"><div class="hl-txt">"A Dutch city's welfare fraud detection algorithm disproportionately flagged residents with foreign-sounding surnames."</div><select class="cat-sel"><option>— Select —</option><option>Job Displacement</option><option>Data Privacy</option><option>Digital Divide</option><option>Social Dynamics</option><option>Healthcare</option><option>Environmental Impact</option></select></div>
      <div class="hl-row"><div class="hl-txt">"Only 34% of rural Belgian households have access to fibre broadband."</div><select class="cat-sel"><option>— Select —</option><option>Job Displacement</option><option>Data Privacy</option><option>Digital Divide</option><option>Social Dynamics</option><option>Healthcare</option><option>Environmental Impact</option></select></div>
      <div class="hl-row"><div class="hl-txt">"An AI chatbot prescribed incorrect medication dosages to 17 patients before the error was detected."</div><select class="cat-sel"><option>— Select —</option><option>Job Displacement</option><option>Data Privacy</option><option>Digital Divide</option><option>Social Dynamics</option><option>Healthcare</option><option>Environmental Impact</option></select></div>
      <div class="hl-row"><div class="hl-txt">"A major fashion retailer replaced its buying team with an AI demand forecasting system."</div><select class="cat-sel"><option>— Select —</option><option>Job Displacement</option><option>Data Privacy</option><option>Digital Divide</option><option>Social Dynamics</option><option>Healthcare</option><option>Environmental Impact</option></select></div>
    </div>
    <div class="cp-note">If you can classify all five confidently — you are ready for Section 03.</div>
  </div>
</section>

<!-- ═══════════════════════════════════════════
     SECTION 2 — ETHICAL ISSUES
═══════════════════════════════════════════ -->
<section id="s2" class="section-dark section">
  <span class="sec-label">Section 03 — Issues</span>
  <h2 class="sec-title" style="color:white">The Ethical Issues Hidden in Plain Sight</h2>
  <p class="sec-intro">These are not edge cases. These are the standard operating conditions of modern AI systems. Every business that uses AI faces these issues. The question is whether they have thought about them deliberately — or not.</p>

  <div class="dcard"><div class="card-n">01 / 06</div><div class="card-t">Algorithmic Bias</div><div class="card-b">ML models learn from historical data. If that data reflects past discrimination, the model encodes it and applies it at scale, invisibly. A biased human decision affects one person. A biased algorithm affects millions simultaneously, with no mechanism for those affected to know it happened.</div><div class="card-ex"><strong>Real Example</strong>Google's Gemini (2024) generated historically inaccurate images — an attempt to correct underrepresentation that introduced a different form of bias. It illustrates how difficult it is to fix bias at the output layer without addressing the training data itself.</div></div>

  <div class="dcard"><div class="card-n">02 / 06</div><div class="card-t">Data Privacy &amp; Consent</div><div class="card-b">The issue is not simply that data is collected — it is that most people do not understand what they are consenting to, and consent mechanisms are designed to obscure rather than clarify.</div><div class="card-ex"><strong>Real Example</strong>WhatsApp (2021): users were presented with "Agree or stop using WhatsApp" — technically consent, but not meaningfully informed. For many users, leaving WhatsApp is effectively no choice at all.</div></div>

  <div class="dcard"><div class="card-n">03 / 06</div><div class="card-t">Surveillance &amp; Civil Liberties</div><div class="card-b">AI-powered surveillance gives institutions the ability to monitor individuals at a scale previously impossible. The same capability that locates a missing child can track a political opponent.</div><div class="card-ex"><strong>Real Example</strong>China's Social Credit System aggregates behavioural data to affect citizens' access to travel, credit, and employment. In Europe: the Belgian DPA ruled that the IAB Europe real-time bidding framework shared user data with hundreds of companies in ways users could not meaningfully control.</div></div>

  <div class="dcard"><div class="card-n">04 / 06</div><div class="card-t">Ethical Decision-Making by Machines</div><div class="card-b">AI systems now make consequential decisions in healthcare triage, criminal sentencing, and credit scoring. A machine cannot be held morally responsible — the responsible party is always a human: the designer, the deployer, or the regulator who permitted it.</div><div class="card-ex"><strong>Real Example</strong>A UK local authority used an algorithmic tool to prioritise child welfare cases. Social workers reported pressure to follow the algorithm even when their professional judgment differed — a systematic override of human expertise.</div></div>

  <div class="dcard"><div class="card-n">05 / 06</div><div class="card-t">Accountability &amp; The Black Box Problem</div><div class="card-b">Many high-performing ML models are fundamentally opaque — even their designers cannot fully explain why a specific output was produced. Harm can be identified, but responsibility cannot be cleanly assigned.</div><div class="card-ex"><strong>Real Example</strong>The EU AI Act (2024) requires high-risk AI systems — in hiring, credit, healthcare, and law enforcement — to be explainable and auditable. Companies that cannot explain how their AI reaches decisions face significant regulatory exposure.</div></div>

  <div class="dcard"><div class="card-n">06 / 06</div><div class="card-t">Deepfakes &amp; The Erosion of Trust</div><div class="card-b">Generative AI can produce highly convincing synthetic audio, video, and images of real people saying or doing things they never did. This creates issues spanning consent, identity, fraud, and the reliability of digital evidence.</div><div class="card-ex"><strong>Real Example</strong>2019: A UK energy CEO transferred €220,000 after an AI-generated voice call impersonating his parent company's CEO. 2024 Slovakia: fabricated AI audio clips of a candidate spread 48hrs before the election. The candidate lost.</div></div>

  <div style="margin:32px 0 24px">
    <span class="sec-label">The AI Development Pipeline — Where Bias Enters</span>
    <div class="pipeline">
      <div class="pipe-step">Data Collection</div><span class="pipe-arrow">→</span>
      <div class="pipe-step">Data Labelling</div><span class="pipe-arrow">→</span>
      <div class="pipe-step">Model Training</div><span class="pipe-arrow">→</span>
      <div class="pipe-step">Testing</div><span class="pipe-arrow">→</span>
      <div class="pipe-step">Deployment</div><span class="pipe-arrow">→</span>
      <div class="pipe-step">Monitoring</div>
    </div>
    <div class="dcallout">Each stage is an ethical checkpoint. Bias that enters at data collection cannot be fully corrected at deployment. Accountability requires identifying which specific checkpoint was missed — and by whom.</div>
  </div>

  <div class="checkpoint">
    <div class="cp-id">2.1 — Bias Detection: Walk the Pipeline</div>
    <div class="cp-type">Type: Structured analysis — apply the pipeline framework to a real pattern</div>
    <div class="cp-scenario"><strong>Scenario:</strong> A tech company builds an AI tool to screen job applications. Trained on ten years of successful hire data, the tool consistently scores applications from graduates of two specific universities higher — regardless of GPA or skills.</div>
    <ul class="cp-qs">
      <li class="cp-q"><span class="q-lbl">QUESTION 1</span>At which stage of the AI development pipeline did the bias most likely originate? Walk through each stage and explain your reasoning.<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 2</span>The hiring manager says: "The algorithm is just reflecting what has historically worked for us." Is this a valid defence? Why or why not?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 3</span>Who should be responsible for fixing this — and who should be responsible for decisions already made using the biased system?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
    </ul>
    <div class="cp-note">This is a real pattern. Amazon's actual hiring algorithm, covered in Section 05, followed exactly this logic.</div>
  </div>

  <div class="checkpoint">
    <div class="cp-id">2.2 — Consent Audit: Was That Really a Choice?</div>
    <div class="cp-type">Type: Critical evaluation — assess a consent interaction from your own experience</div>
    <ul class="cp-qs">
      <li class="cp-q"><span class="q-lbl">QUESTION 1</span>Recall the last time you clicked "Accept" on a cookie banner or terms of service. Did you read what you were accepting? If not — why not?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 2</span>Would reading it have changed your decision? If the answer is no — what does that tell you about how consent is being used in that interaction?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 3</span>A Deontologist would argue: "Consent obtained through deliberate complexity is not meaningful consent." A Consequentialist might counter: "The service is useful, the data improves it — the outcome justifies the process." Which do you find more convincing, and why?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
    </ul>
    <div class="cp-note">You have just performed your first framework comparison. Remember this moment — you will need it in Section 04.</div>
  </div>

  <div class="checkpoint">
    <div class="cp-id">2.3 — The Surveillance Spectrum: Where Is Your Line?</div>
    <div class="cp-type">Type: Boundary drawing — commit to a position, then name the principle you used</div>
    <p style="color:rgba(255,255,255,0.7);font-size:14px;margin-bottom:16px;line-height:1.7">For each scenario, decide: <strong style="color:#34d399">Yes / Acceptable</strong> — <strong style="color:#c0392b">No</strong> — <strong style="color:#fbbf24">With Conditions</strong></p>
    <div id="surv-rows">
      <div class="surv-row"><div class="surv-txt">1. A supermarket uses facial recognition to identify known shoplifters.</div><div class="surv-btns"><button class="surv-btn" onclick="setSurv(this,'ok')">Yes</button><button class="surv-btn" onclick="setSurv(this,'no')">No</button><button class="surv-btn" onclick="setSurv(this,'cond')">Cond.</button></div></div>
      <div class="surv-row"><div class="surv-txt">2. An employer tracks which applications are open on remote employees' computers during working hours.</div><div class="surv-btns"><button class="surv-btn" onclick="setSurv(this,'ok')">Yes</button><button class="surv-btn" onclick="setSurv(this,'no')">No</button><button class="surv-btn" onclick="setSurv(this,'cond')">Cond.</button></div></div>
      <div class="surv-row"><div class="surv-txt">3. A city council uses AI to monitor crowd density in public spaces to prevent stampedes.</div><div class="surv-btns"><button class="surv-btn" onclick="setSurv(this,'ok')">Yes</button><button class="surv-btn" onclick="setSurv(this,'no')">No</button><button class="surv-btn" onclick="setSurv(this,'cond')">Cond.</button></div></div>
      <div class="surv-row"><div class="surv-txt">4. A hospital uses AI to continuously monitor patient vitals and alert staff before a condition becomes critical.</div><div class="surv-btns"><button class="surv-btn" onclick="setSurv(this,'ok')">Yes</button><button class="surv-btn" onclick="setSurv(this,'no')">No</button><button class="surv-btn" onclick="setSurv(this,'cond')">Cond.</button></div></div>
      <div class="surv-row"><div class="surv-txt">5. A government uses social media sentiment analysis to identify citizens likely to participate in protests.</div><div class="surv-btns"><button class="surv-btn" onclick="setSurv(this,'ok')">Yes</button><button class="surv-btn" onclick="setSurv(this,'no')">No</button><button class="surv-btn" onclick="setSurv(this,'cond')">Cond.</button></div></div>
      <div class="surv-row"><div class="surv-txt">6. An insurance company uses smartphone accelerometer data to assess driving aggression and price premiums accordingly.</div><div class="surv-btns"><button class="surv-btn" onclick="setSurv(this,'ok')">Yes</button><button class="surv-btn" onclick="setSurv(this,'no')">No</button><button class="surv-btn" onclick="setSurv(this,'cond')">Cond.</button></div></div>
    </div>
    <div class="cp-q" style="margin-top:16px"><span class="q-lbl">REFLECTION QUESTION</span>Look at your six answers. What principle were you using to draw the line between acceptable and unacceptable? Name it explicitly in one sentence.<textarea class="cp-input" placeholder="My principle for drawing this line was..."></textarea></div>
    <div class="cp-note">That principle is the beginning of your ethical framework.</div>
  </div>

  <div class="checkpoint">
    <div class="cp-id">2.4 — The Trolley Problem, Updated</div>
    <div class="cp-type">Type: Ethical dilemma — no single correct answer, but reasoning must be framework-anchored</div>
    <div class="cp-scenario"><strong>Scenario:</strong> An AI triage system in a hospital emergency department assigns lower priority to an 80-year-old patient with a serious but treatable condition, directing staff to three younger patients assessed as more urgent. The 80-year-old's condition deteriorates. She later sues the hospital. <em>Variations of this scenario are happening in hospitals across Europe right now.</em></div>
    <ul class="cp-qs">
      <li class="cp-q"><span class="q-lbl">QUESTION 1</span>Was the algorithm's decision ethically justified? Use one framework to support your answer.<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 2</span>Who is responsible — the hospital, the developer, the staff who followed the output, or some combination?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 3</span>Should there have been a human override mechanism? If yes — what would appropriate human oversight look like in practice in a busy emergency department?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
    </ul>
  </div>

  <div class="checkpoint">
    <div class="cp-id">2.5 — The Synthetic Evidence Problem: Design a Response</div>
    <div class="cp-type">Type: Policy design — think constructively, not just critically</div>
    <div class="cp-scenario"><strong>Scenario:</strong> You work in legal compliance at a major Belgian bank. AI voice cloning technology can now replicate a person's voice from as little as three seconds of audio — and is already being used in financial fraud. Your bank currently uses voice recognition as a customer authentication method.</div>
    <ul class="cp-qs">
      <li class="cp-q"><span class="q-lbl">QUESTION 1</span>What is the specific ethical and business risk this creates for your institution?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 2</span>What would you recommend replacing or supplementing voice authentication with — and what new ethical risks does your recommendation introduce?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 3</span>A colleague suggests: "We should not tell customers we are removing voice authentication, because it will undermine confidence in our security systems." Evaluate this using any ethical framework you have encountered.<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
    </ul>
  </div>

  <div class="checkpoint">
    <div class="cp-id">2.6 — Issue Mapping: Connect the Dots</div>
    <div class="cp-type">Type: Synthesis — see connections across issues, not just isolated problems</div>
    <ul class="cp-qs">
      <li class="cp-q"><span class="q-lbl">QUESTION 1</span>Algorithmic Bias &amp; The Black Box Problem: why does opacity make bias harder to identify and fix?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 2</span>Data Privacy &amp; Surveillance: why does the erosion of privacy enable surveillance to expand?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 3</span>Ethical Decision-Making by Machines &amp; Accountability: why does automation make responsibility harder to assign?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 4</span>Which of the six ethical issues is the most structurally difficult to solve — not the most serious in terms of harm, but the hardest to fix even if everyone wanted to? Explain your reasoning.<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
    </ul>
    <div class="cp-note">Now you are ready for the tools. Section 04 gives you frameworks to argue your position with rigour.</div>
  </div>
</section>

<!-- TRANSITION -->
<div class="transition">
  <div>
    <div class="trans-line"></div>
    <p class="trans-text">"You have just seen what happens when real companies made these decisions without adequate ethical frameworks. Now you have the tools. The question is whether you would have used them."</p>
    <div class="trans-line"></div>
  </div>
</div>

<!-- ═══════════════════════════════════════════
     SECTION 3 — FRAMEWORKS
═══════════════════════════════════════════ -->
<section id="s3" class="section-mid section">
  <span class="sec-label">Section 04 — Frameworks</span>
  <h2 class="sec-title" style="color:white">Five Frameworks for Ethical Analysis</h2>
  <p class="sec-intro">An opinion about AI is not an argument. An argument needs a framework — a structured set of principles that tells you what counts as an ethical reason, and what does not.</p>
  <div class="dcallout amber"><strong style="color:#fbbf24">Assignment requirement:</strong> Your executive report must apply <strong>Consequentialism plus at least one other framework.</strong> Using only one framework is not analysis — it is advocacy.</div>

  <div class="fw-tabs">
    <button class="fw-tab active" onclick="showFw('consequentialism',this)">Consequentialism</button>
    <button class="fw-tab" onclick="showFw('deontological',this)">Deontological</button>
    <button class="fw-tab" onclick="showFw('virtue',this)">Virtue Ethics</button>
    <button class="fw-tab" onclick="showFw('rights',this)">Rights-Based</button>
    <button class="fw-tab" onclick="showFw('fairness',this)">Fairness &amp; Justice</button>
  </div>

  <div id="fw-consequentialism" class="fw-panel active">
    <div class="fw-principle">"The most ethical action produces the greatest good for the greatest number."</div>
    <p style="color:rgba(255,255,255,0.7);font-size:14px;line-height:1.8;margin-bottom:20px"><strong style="color:white">Application to AI:</strong> Evaluate technology by aggregate impact — lives saved, costs reduced, access improved. An AI cancer diagnostic tool correct 97% of the time may be ethical even if it occasionally errs, because the net benefit is enormous.</p>
    <div class="fw-grid">
      <div class="fw-box fw-str"><div class="fw-blbl">✓ Strength</div><div class="fw-btext">Forces decision-makers to think seriously about real-world scale and impact. Essential for policy-level analysis where aggregate outcomes matter.</div></div>
      <div class="fw-box fw-lim"><div class="fw-blbl">✗ Limitation</div><div class="fw-btext">Can justify troubling means if ends are sufficiently positive. A 2% error rate sounds small until the system processes 10 million decisions.</div></div>
    </div>
    <div class="dcallout"><strong style="color:#60a5fa">Applied example:</strong> The Cambridge Analytica data collection also funded voter registration campaigns. A pure consequentialist might ask: did it increase participation? Most people instinctively reject this. That instinct is pointing at a different framework.</div>
  </div>

  <div id="fw-deontological" class="fw-panel">
    <div class="fw-principle">"Some actions are intrinsically wrong, regardless of their outcomes."</div>
    <p style="color:rgba(255,255,255,0.7);font-size:14px;line-height:1.8;margin-bottom:20px"><strong style="color:white">Application to AI:</strong> Collecting data without genuine informed consent is wrong — even if the data cures disease. The violation of individual autonomy is the ethical problem, not its consequences. GDPR is largely a codification of deontological reasoning applied to data rights.</p>
    <div class="fw-grid">
      <div class="fw-box fw-str"><div class="fw-blbl">✓ Strength</div><div class="fw-btext">Creates clear, non-negotiable lines. Protects individuals from being sacrificed for aggregate benefit. Answers directly whether an act was permissible — not just whether it turned out well.</div></div>
      <div class="fw-box fw-lim"><div class="fw-blbl">✗ Limitation</div><div class="fw-btext">Duties can conflict. The duty to protect privacy can clash with the duty to prevent harm — e.g., mandatory contact tracing during a pandemic.</div></div>
    </div>
    <div class="dcallout"><strong style="color:#60a5fa">Applied example:</strong> Amazon's hiring algorithm penalised women's CVs. From a deontological view, building a system with discriminatory criteria was wrong — regardless of whether it deployed at scale.</div>
  </div>

  <div id="fw-virtue" class="fw-panel">
    <div class="fw-principle">"What would a person — or institution — of good character do in this situation?"</div>
    <p style="color:rgba(255,255,255,0.7);font-size:14px;line-height:1.8;margin-bottom:20px"><strong style="color:white">Application to AI:</strong> Evaluate not just the system, but the organisation that built it. A company that proactively publishes bias audits, pays for independent ethical reviews, and communicates transparently about limitations demonstrates institutional virtue — even if its systems are imperfect.</p>
    <div class="fw-grid">
      <div class="fw-box fw-str"><div class="fw-blbl">✓ Strength</div><div class="fw-btext">Captures what rules and outcomes miss: intent, transparency, responsiveness, and institutional culture. Explains why two companies with similar systems can be judged very differently.</div></div>
      <div class="fw-box fw-lim"><div class="fw-blbl">✗ Limitation</div><div class="fw-btext">Highly subjective. Does not provide clear procedural guidance for novel situations. Two observers can assess the same company's response very differently.</div></div>
    </div>
    <div class="dcallout"><strong style="color:#60a5fa">Applied example:</strong> Apple made privacy a product differentiator and committed publicly to data-limiting design. Facebook buried internal research showing harm to users. Virtue ethics captures that distinction; consequentialism struggles to.</div>
  </div>

  <div id="fw-rights" class="fw-panel">
    <div class="fw-principle">"Individuals possess fundamental rights that cannot be overridden by majority benefit."</div>
    <p style="color:rgba(255,255,255,0.7);font-size:14px;line-height:1.8;margin-bottom:20px"><strong style="color:white">Application to AI:</strong> The right to privacy, to non-discrimination, to an explanation of automated decisions — these are not trade-offs in a cost-benefit analysis. The EU AI Act (2024) makes this framework legally enforceable, <strong>prohibiting</strong> social scoring, real-time biometric surveillance in public spaces, and subliminal manipulation, while classifying AI in hiring, credit, healthcare, and criminal justice as <strong>high-risk</strong> requiring human oversight.</p>
    <div class="fw-grid">
      <div class="fw-box fw-str"><div class="fw-blbl">✓ Strength</div><div class="fw-btext">Provides clear, enforceable protections. Directly connected to European legal frameworks students will navigate professionally.</div></div>
      <div class="fw-box fw-lim"><div class="fw-blbl">✗ Limitation</div><div class="fw-btext">Rights can conflict — security vs. privacy; freedom of expression vs. protection from harm. Does not resolve these conflicts cleanly.</div></div>
    </div>
    <div class="dcallout"><strong style="color:#60a5fa">Applied example:</strong> COMPAS recidivism algorithm informed criminal sentences using a proprietary, unauditable algorithm — a direct violation of due process rights regardless of aggregate accuracy.</div>
  </div>

  <div id="fw-fairness" class="fw-panel">
    <div class="fw-principle">"Are the burdens and benefits of this technology distributed equitably?"</div>
    <p style="color:rgba(255,255,255,0.7);font-size:14px;line-height:1.8;margin-bottom:20px"><strong style="color:white">Application to AI:</strong> Who bears the downside of AI — job displacement, surveillance, biased decisions? Who captures the upside — efficiency gains, cost savings, convenience? When these are consistently different groups, there is a justice problem other frameworks may miss.</p>
    <div class="fw-grid">
      <div class="fw-box fw-str"><div class="fw-blbl">✓ Strength</div><div class="fw-btext">Directly addresses structural inequality. Asks not just "was it ethical?" but "ethical for whom?" Most relevant when analysing AI's impact on marginalised communities.</div></div>
      <div class="fw-box fw-lim"><div class="fw-blbl">✗ Limitation</div><div class="fw-btext">"Fairness" is technically complex and politically contested. Multiple mathematically valid definitions of fairness are mutually incompatible. A system can be fair in one sense and deeply unfair in another.</div></div>
    </div>
    <div class="dcallout"><strong style="color:#60a5fa">Applied example:</strong> COMPAS was statistically accurate in aggregate — but its false positive rate fell twice as heavily on Black defendants. Consequentialism might defend it; Fairness &amp; Justice cannot.</div>
  </div>

  <div class="checkpoint">
    <div class="cp-id">3.1 — Consequentialism Under Pressure</div>
    <div class="cp-type">Type: Stress test — find the limits of the framework</div>
    <div class="cp-scenario"><strong>Scenario:</strong> A ride-hailing company's algorithm identifies that routes through certain neighbourhoods are associated with higher cancellation rates. It begins deprioritising pickups from those areas during peak hours. Driver satisfaction improves 8%, cancellations fall 12%. The deprioritised neighbourhoods have higher proportions of ethnic minority residents.</div>
    <ul class="cp-qs">
      <li class="cp-q"><span class="q-lbl">QUESTION 1</span>How would a Consequentialist evaluate this decision? What additional data would they require to reach a verdict?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 2</span>Is improving overall system performance a sufficient justification for an outcome that falls disproportionately on one demographic group?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 3</span>At what point does a "statistically justified" decision become discrimination? Is there a threshold — or is the question about something other than numbers?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
    </ul>
  </div>

  <div class="checkpoint">
    <div class="cp-id">3.2 — Two Frameworks, One Case: Return to the Nurse</div>
    <div class="cp-type">Type: Structured comparison — apply two frameworks to the same scenario and compare the verdicts</div>
    <div class="cp-scenario"><strong>Return to Checkpoint 0.1:</strong> The European bank's AI system processes mortgage applications with no human review. A nurse with a clean credit history is rejected with no explanation.</div>
    <ul class="cp-qs">
      <li class="cp-q"><span class="q-lbl">QUESTION 1 — CONSEQUENTIALISM</span>Is the system ethical? Consider: faster processing, lower costs, higher overall approval rates. What evidence would you need?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 2 — DEONTOLOGICAL ETHICS</span>Is the system ethical? Consider: the nurse's right to an explanation, the right to human review, and Article 22 of GDPR — the right not to be subject to solely automated decision-making.<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 3</span>If the two frameworks produce different verdicts — which do you find more persuasive, and why? If they agree — are you sure you applied both independently?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
    </ul>
    <div class="cp-note">This is exactly the analytical structure your executive report requires.</div>
  </div>

  <div class="checkpoint">
    <div class="cp-id">3.3 — The EU AI Act in Practice</div>
    <div class="cp-type">Type: Regulatory application — classify real AI systems under the actual law</div>
    <p style="color:rgba(255,255,255,0.7);font-size:14px;margin-bottom:16px;line-height:1.7">Classify each application as: <strong>Prohibited</strong> / <strong>High-Risk (regulated)</strong> / <strong>Lower-Risk</strong></p>
    <div id="euai-rows">
      <div class="euai-row"><div class="euai-txt">1. An AI tool that screens job applications and produces shortlists for human review.</div><select class="euai-sel"><option>— Classify —</option><option>Prohibited</option><option>High-Risk</option><option>Lower-Risk</option></select></div>
      <div class="euai-row"><div class="euai-txt">2. A chatbot on a retail website that answers product questions.</div><select class="euai-sel"><option>— Classify —</option><option>Prohibited</option><option>High-Risk</option><option>Lower-Risk</option></select></div>
      <div class="euai-row"><div class="euai-txt">3. A facial recognition system at an airport verifying passenger identity against their passport.</div><select class="euai-sel"><option>— Classify —</option><option>Prohibited</option><option>High-Risk</option><option>Lower-Risk</option></select></div>
      <div class="euai-row"><div class="euai-txt">4. An AI system that assigns social welfare eligibility scores to citizens based on lifestyle data.</div><select class="euai-sel"><option>— Classify —</option><option>Prohibited</option><option>High-Risk</option><option>Lower-Risk</option></select></div>
      <div class="euai-row"><div class="euai-txt">5. A recommendation engine suggesting which Netflix series to watch next.</div><select class="euai-sel"><option>— Classify —</option><option>Prohibited</option><option>High-Risk</option><option>Lower-Risk</option></select></div>
      <div class="euai-row"><div class="euai-txt">6. An AI tool used by a Belgian court to calculate sentencing recommendations.</div><select class="euai-sel"><option>— Classify —</option><option>Prohibited</option><option>High-Risk</option><option>Lower-Risk</option></select></div>
    </div>
    <div class="cp-q" style="margin-top:16px"><span class="q-lbl">REFLECTION</span>Two of these may feel like they should be regulated more strictly than the law currently requires. Which two — and what does your answer tell you about the limits of any regulatory framework?<textarea class="cp-input" placeholder="Write your response here..."></textarea></div>
  </div>

  <div class="checkpoint">
    <div class="cp-id">3.4 — Who Bears the Cost?</div>
    <div class="cp-type">Type: Distribution analysis — surface assumptions about who matters in a business decision</div>
    <div class="cp-scenario"><strong>Scenario:</strong> A major Belgian retail chain deploys an AI pricing and inventory system that increases profit margins 18% and reduces food waste 22%. It does this in part by withdrawing low-margin product lines — products disproportionately purchased by lower-income customers who relied on them for affordable nutrition.</div>
    <ul class="cp-qs">
      <li class="cp-q"><span class="q-lbl">QUESTION 1</span>Evaluate this decision using Fairness &amp; Justice. Who captured the benefit? Who bore the cost?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 2</span>The CEO argues: "We are a business, not a social service. Maximising shareholder value is our primary obligation." Evaluate this argument using two frameworks.<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 3</span>Is there a version of this AI deployment that produces the same efficiency gains without the distributional harm? If yes — what would it require? If no — what does that imply about whether the system should be deployed?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
    </ul>
  </div>

  <!-- FRAMEWORK COMPARISON TOOL -->
  <div style="margin:40px 0 24px">
    <span class="sec-label">Framework Comparison Tool — Predictive Policing Case</span>
    <div class="fcomp-case"><strong style="color:white">Scenario:</strong> A major European city deploys a predictive policing algorithm that analyses historical crime data, patrol logs, and socioeconomic indicators to direct police resources toward "high-risk areas." The system has been running for 18 months. Overall reported crime has fallen 7%. Complaints of over-policing from specific neighbourhoods have increased 34%.<br><br>Select a framework to see how it would analyse this case.</div>
    <div class="fcomp-tabs fw-tabs">
      <button class="fw-tab active" onclick="showFcomp('c',this)">Consequentialism</button>
      <button class="fw-tab" onclick="showFcomp('d',this)">Deontological</button>
      <button class="fw-tab" onclick="showFcomp('v',this)">Virtue</button>
      <button class="fw-tab" onclick="showFcomp('r',this)">Rights-Based</button>
      <button class="fw-tab" onclick="showFcomp('f',this)">Fairness &amp; Justice</button>
    </div>
    <div id="fcomp-c" class="fcomp-verdict"><span class="fcomp-lbl">CONSEQUENTIALISM VERDICT</span>A Consequentialist asks: does the algorithm reduce crime? If crime rates fall in targeted areas, the aggregate good may appear to justify the system. However, they would also need to account for all costs: wrongful stops, community trust erosion, and the long-term harm of normalising racially disparate policing. The consequentialist case is not as clean as it first appears.</div>
    <div id="fcomp-d" class="fcomp-verdict" style="display:none"><span class="fcomp-lbl">DEONTOLOGICAL VERDICT</span>A Deontologist focuses on the intrinsic rights violation: individuals in targeted neighbourhoods are subjected to increased state surveillance based on where they live, not what they have done. This treats people as means rather than ends — a categorical wrong regardless of effectiveness.</div>
    <div id="fcomp-v" class="fcomp-verdict" style="display:none"><span class="fcomp-lbl">VIRTUE ETHICS VERDICT</span>A Virtue Ethicist asks: what does deploying this algorithm reveal about the character of the institution? A city that adopts a predictive system without independent bias audits, without consulting affected communities, and without transparent reporting mechanisms demonstrates institutional vice — regardless of stated intentions.</div>
    <div id="fcomp-r" class="fcomp-verdict" style="display:none"><span class="fcomp-lbl">RIGHTS-BASED VERDICT</span>A Rights-Based analysis finds multiple violations: the right to equal protection under law, the right not to be subjected to discriminatory treatment, and the right to an explanation of automated decisions. These rights cannot be traded against efficiency gains. The system fails a rights test categorically.</div>
    <div id="fcomp-f" class="fcomp-verdict" style="display:none"><span class="fcomp-lbl">FAIRNESS &amp; JUSTICE VERDICT</span>A Fairness &amp; Justice analysis asks: who bears the cost of this algorithm's errors? If false positives — stops of innocent people — fall disproportionately on Black and immigrant communities, the distribution of harm is unjust regardless of aggregate accuracy. Efficiency gains do not compensate specific communities for bearing a disproportionate burden.</div>
  </div>

  <div class="checkpoint">
    <div class="cp-id">3.5 — Build Your Own Argument</div>
    <div class="cp-type">Type: Constructive argumentation — argue both sides before committing to your own position</div>
    <div class="cp-scenario"><strong>Question:</strong> Should a European hospital be permitted to use an AI system to make initial triage decisions in its emergency department — without requiring a clinician to review each recommendation before it is acted upon?</div>
    <ul class="cp-qs">
      <li class="cp-q"><span class="q-lbl">STEP 1 — ARGUE IN FAVOUR (using Consequentialism)</span>Write the strongest possible argument in favour.<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">STEP 2 — ARGUE AGAINST (using Rights-Based or Deontological Ethics)</span>Write the strongest possible argument against.<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">STEP 3 — YOUR POSITION</span>State your own position, identify which framework you find most persuasive in this context — and explicitly acknowledge the strongest objection to your view.<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
    </ul>
    <div class="cp-note">An argument that cannot acknowledge its strongest objection is not yet an argument. It is an assertion.</div>
  </div>
</section>

<!-- ═══════════════════════════════════════════
     SECTION 4 — CASE STUDIES
═══════════════════════════════════════════ -->
<section id="s4" class="section-dark section">
  <span class="sec-label">Section 05 — Cases</span>
  <h2 class="sec-title" style="color:white">Three Cases That Changed the Conversation</h2>
  <p class="sec-intro">The most useful thing about these cases is not what went wrong. It is that the people inside these companies thought they were making reasonable decisions. Understanding how reasonable people produce ethical failures is more useful than assuming bad actors are the problem.</p>

  <!-- CASE A -->
  <div style="margin-bottom:48px">
    <div class="case-hdr"><div class="case-letter">A</div><div><div class="case-t">Amazon's Hiring Algorithm</div><div class="case-yr">2018 · Algorithmic Bias · HR Technology</div></div></div>
    <p class="case-body">Amazon built a machine learning tool to screen CVs, trained on ten years of historical hiring data. Because Amazon's technical workforce had been predominantly male, the model learned to associate male-coded language with successful hires. It penalised CVs containing the word "women's" — as in "women's chess club" — and downgraded graduates of all-women's colleges. Amazon discovered the bias and scrapped the tool before full deployment.</p>
    <span class="sec-label">Multi-Framework Analysis</span>
    <div class="verdict v-c"><span class="v-lbl">CONSEQUENTIALISM</span>The harm was contained — caught before widespread deployment. But a tool like this at scale, replicated across industries, would systematically exclude qualified women from technical roles for a generation. Being caught does not redeem the design process.</div>
    <div class="verdict v-d"><span class="v-lbl">DEONTOLOGICAL ETHICS</span>Building a system that applied gender-based criteria — even implicitly — was wrong regardless of outcome. Candidates have a right not to be discriminated against on the basis of gender. That right was violated by the design itself.</div>
    <div class="verdict v-f"><span class="v-lbl">FAIRNESS &amp; JUSTICE</span>The system did not merely reflect historical inequality. It perpetuated it, encoded it, and would have applied it at machine speed across thousands of hiring decisions.</div>
    <div class="acc-chain">
      <div class="acc-lbl">ACCOUNTABILITY CHAIN</div>
      <div class="acc-items">
        <div class="acc-item">Data team&#10;(biased training data,&#10;no demographic audit)</div><span class="acc-arr">→</span>
        <div class="acc-item">ML engineers&#10;(no bias testing)</div><span class="acc-arr">→</span>
        <div class="acc-item">HR leadership&#10;(approved without&#10;independent review)</div><span class="acc-arr">→</span>
        <div class="acc-item">Amazon as institution&#10;(no standard bias&#10;auditing practice)</div>
      </div>
    </div>
    <div class="never-asked"><div class="na-lbl">THE QUESTION NEVER ASKED</div><div class="na-q">"If our historical hiring decisions were biased — and our training data shows they were — should we be building a model designed to replicate them?"</div></div>
  </div>

  <div class="checkpoint">
    <div class="cp-id">4.1 — The Amazon Case: Your Verdict</div>
    <div class="cp-type">Type: Structured judgment — produce a framework-anchored position</div>
    <ul class="cp-qs">
      <li class="cp-q"><span class="q-lbl">QUESTION 1</span>Amazon's engineers were not trying to build a discriminatory tool — they were trying to build an efficient one. Does intent change the ethical verdict? Which framework is most helpful in answering that question?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 2</span>Amazon detected the bias and stopped the project. Under Virtue Ethics — does catching and correcting a problem redeem the organisation for having created it? What additional information would you need to answer definitively?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 3</span>If you were Head of AI Ethics at Amazon in 2016, what specific process change would you have recommended — and at which pipeline stage would you have intervened?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
    </ul>
  </div>

  <!-- CASE B -->
  <div style="margin-bottom:48px">
    <div class="case-hdr"><div class="case-letter">B</div><div><div class="case-t">Facebook &amp; Cambridge Analytica</div><div class="case-yr">2018 · Data Privacy · Political Targeting · Platform Accountability</div></div></div>
    <p class="case-body">A researcher developed a Facebook quiz app that collected personality data from 270,000 users who consented to academic research. Through Facebook's platform permissions, the app also harvested data from those users' friends — without their knowledge or consent — providing access to approximately 87 million profiles. That data was sold to Cambridge Analytica, which used it for political micro-targeting in the 2016 US election and the Brexit referendum. Facebook had known about the data misuse since 2015 — three years before it became public.</p>
    <span class="sec-label">Multi-Framework Analysis</span>
    <div class="verdict v-r"><span class="v-lbl">RIGHTS-BASED ETHICS</span>The violation is categorical. 87 million people's data was used for purposes they had not consented to, in a domain — political persuasion — with significant consequences for democratic processes. No aggregate benefit justifies this.</div>
    <div class="verdict v-c"><span class="v-lbl">CONSEQUENTIALISM</span>Even if direct electoral impact was marginal, the normalisation of data-driven political manipulation carries long-term institutional costs that dwarf any short-term campaign benefit.</div>
    <div class="verdict v-v"><span class="v-lbl">VIRTUE ETHICS</span>Facebook knew since 2015 and took limited action. When the story broke in 2018, leadership's initial response was to dispute the framing and minimise. The absence of proactive disclosure demonstrates an institution that prioritised reputation over accountability.</div>
    <div class="acc-chain">
      <div class="acc-lbl">ACCOUNTABILITY CHAIN</div>
      <div class="acc-items">
        <div class="acc-item">Researcher&#10;(harvested &amp; sold data)</div><span class="acc-arr">→</span>
        <div class="acc-item">Cambridge Analytica&#10;(political targeting)</div><span class="acc-arr">→</span>
        <div class="acc-item">Facebook policies&#10;(permitted harvesting&#10;at scale)</div><span class="acc-arr">→</span>
        <div class="acc-item">Facebook leadership&#10;(knew, did not act)</div><span class="acc-arr">→</span>
        <div class="acc-item">US/UK regulators&#10;(ignored early&#10;warnings)</div>
      </div>
    </div>
    <div class="never-asked"><div class="na-lbl">THE QUESTION NEVER ASKED</div><div class="na-q">"We have built a system that technically permits third parties to harvest our users' friends' data without consent. Should our terms of service making this permissible make us comfortable?"</div></div>
  </div>

  <div class="checkpoint">
    <div class="cp-id">4.2 — The Facebook Case: Distributed Responsibility</div>
    <div class="cp-type">Type: Accountability mapping — responsibility as a chain, not a single point</div>
    <div class="cp-scenario"><strong>Scenario:</strong> It is 2015. You are a privacy policy manager at Facebook. A researcher informs your team that a third-party app has been harvesting friend data at scale and sharing it with a political consultancy. The platform's terms of service technically permit this.</div>
    <ul class="cp-qs">
      <li class="cp-q"><span class="q-lbl">QUESTION 1</span>What would you recommend doing — and what internal obstacles would you face making that recommendation?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 2</span>Your legal team says: "We are technically compliant with our own terms of service. There is no legal obligation to act." Is technical compliance a sufficient ethical standard? Which framework answers this most clearly?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 3</span>Three years later, the story breaks publicly. You are still at the company. You knew in 2015. What is your personal ethical responsibility now?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
    </ul>
  </div>

  <!-- CASE C -->
  <div style="margin-bottom:48px">
    <div class="case-hdr"><div class="case-letter">C</div><div><div class="case-t">COMPAS Recidivism Algorithm</div><div class="case-yr">2016–ongoing · Algorithmic Bias · Criminal Justice · Black Box Accountability</div></div></div>
    <p class="case-body">COMPAS is a proprietary AI tool used by courts in several US states to assess the likelihood that a defendant will reoffend — a score that can influence bail, sentencing, and parole. ProPublica's 2016 investigation found that COMPAS assigned significantly higher risk scores to Black defendants than white defendants with equivalent criminal histories. Black defendants who did not reoffend were nearly twice as likely to be falsely flagged as high-risk. The company refused to release the algorithm for independent audit, citing trade secrets.</p>
    <span class="sec-label">Multi-Framework Analysis</span>
    <div class="verdict v-f"><span class="v-lbl">FAIRNESS &amp; JUSTICE</span>The differential error rates constitute structural discrimination applied through a judicial process. Regardless of aggregate accuracy, a system that systematically over-incarcerates one racial group is producing an unjust distribution of a severe harm — loss of liberty.</div>
    <div class="verdict v-d"><span class="v-lbl">DEONTOLOGICAL ETHICS</span>Using an opaque, proprietary algorithm to inform a criminal sentence — without the defendant's right to understand or challenge the logic — violates fundamental due process rights. The right to confront the evidence against you is foundational to a rights-based justice system.</div>
    <div class="verdict v-c"><span class="v-lbl">CONSEQUENTIALISM</span>The aggregate harm of wrongful or disproportionate incarceration is enormous. Beyond individual harm, mass incarceration of a specific demographic group produces cascading consequences — broken families, communities, employment records, and cycles of disadvantage extending across generations.</div>
    <div class="acc-chain">
      <div class="acc-lbl">ACCOUNTABILITY CHAIN</div>
      <div class="acc-items">
        <div class="acc-item">Northpointe/Equivant&#10;(built opaque biased system)</div><span class="acc-arr">→</span>
        <div class="acc-item">Courts&#10;(adopted without&#10;validation)</div><span class="acc-arr">→</span>
        <div class="acc-item">Judges&#10;(deferred without&#10;scrutiny)</div><span class="acc-arr">→</span>
        <div class="acc-item">Legislators&#10;(permitted proprietary&#10;tools in courts)</div><span class="acc-arr">→</span>
        <div class="acc-item">Justice system&#10;("algorithmic" ≠ "objective")</div>
      </div>
    </div>
    <div class="never-asked"><div class="na-lbl">THE QUESTION NEVER ASKED</div><div class="na-q">"The algorithm is proprietary and we cannot audit it. Should we be using it to inform decisions about whether a person goes to prison?"</div></div>
  </div>

  <div class="checkpoint">
    <div class="cp-id">4.3 — The COMPAS Case: The Hardest One</div>
    <div class="cp-type">Type: Deep analysis — the most ethically complex checkpoint in this site</div>
    <ul class="cp-qs">
      <li class="cp-q"><span class="q-lbl">QUESTION 1</span>Northpointe argued COMPAS was statistically fair because it produced equally accurate predictions across racial groups in aggregate. ProPublica argued it was unfair because the false-positive rate fell disproportionately on Black defendants. Both claims are mathematically defensible. How is this possible — and what does it reveal about the concept of "algorithmic objectivity"?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 2</span>A judge is presented with a COMPAS risk score alongside all other case evidence. She personally believes the defendant is low-risk, but the algorithm says high-risk. She has no access to the algorithm's reasoning. What should she do — and which framework most clearly supports her answer?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 3</span>The EU AI Act would classify COMPAS as prohibited or severely restricted if deployed in Europe. Do you think this position is correct — or does it go too far? Argue using the framework you find most persuasive.<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">FINAL REFLECTION</span>Of the three cases, which is the most ethically serious — and which is the most difficult to fix? These are not the same question. Explain why not.<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
    </ul>
  </div>
</section>

<!-- ═══════════════════════════════════════════
     SECTION 5 — YOUR AUDIT
═══════════════════════════════════════════ -->
<section id="s5" class="section-dark section">
  <span class="sec-label">Section 06 — Your Case</span>
  <h2 class="sec-title" style="color:white">The Ethical Audit</h2>
  <p class="sec-intro">You have studied what went wrong in other companies with the benefit of hindsight. Now remove the hindsight. You are inside your own business case, before anything has gone wrong. What do you see?</p>

  <div class="audit-cluster">
    <div class="audit-ctitle">Cluster 1 — Your Data</div>
    <div class="audit-q"><div class="audit-num">1</div><div class="audit-txt">What personal data does your solution collect — and can you state, in one sentence, why each piece is strictly necessary for the system to function? If you cannot, you may be collecting too much.</div></div>
    <div class="audit-q"><div class="audit-num">2</div><div class="audit-txt">Could the data you use to train or inform your system encode historical patterns that disadvantage a specific group? Who was not in the room when that data was collected?</div></div>
  </div>
  <div class="audit-cluster">
    <div class="audit-ctitle">Cluster 2 — Your Decisions</div>
    <div class="audit-q"><div class="audit-num">3</div><div class="audit-txt">At what point in your system does an automated decision produce a consequence for a real person — and is there a human review mechanism before that consequence is enacted?</div></div>
    <div class="audit-q"><div class="audit-num">4</div><div class="audit-txt">If your system produces a harmful output, can you explain — in plain language, to the person affected — how and why that output was reached?</div></div>
  </div>
  <div class="audit-cluster">
    <div class="audit-ctitle">Cluster 3 — Your Distribution</div>
    <div class="audit-q"><div class="audit-num">5</div><div class="audit-txt">Map the beneficiaries and cost-bearers of your solution. Are they the same people? If not — is the distribution equitable, and have you designed any mechanism to address the imbalance?</div></div>
    <div class="audit-q"><div class="audit-num">6</div><div class="audit-txt">Which regulatory framework governs your solution — GDPR, the EU AI Act, sector-specific regulation, or none? If "none" — does that mean it is genuinely unregulated, or that you have not yet found the relevant framework?</div></div>
  </div>

  <div class="checkpoint">
    <div class="cp-id">5.1 — The Assumption You Haven't Examined</div>
    <div class="cp-type">Type: Self-directed critical reflection — the most important checkpoint in this site</div>
    <ul class="cp-qs">
      <li class="cp-q"><span class="q-lbl">QUESTION 1</span>What is one assumption your business case is currently making — about users, data, decision-making, or outcomes — that you have not yet examined critically?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 2</span>What would change in your executive report if that assumption turned out to be wrong?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 3</span>Why haven't you examined it yet? Is it because it genuinely seemed unimportant — or because examining it might complicate a conclusion you are already committed to?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
    </ul>
    <div class="cp-note">The answer to Question 3 is the most important thing you will write today.</div>
  </div>

  <div class="checkpoint">
    <div class="cp-id">5.2 — Red Team Your Own Case</div>
    <div class="cp-type">Type: Adversarial thinking — argue against your own solution</div>
    <div class="cp-scenario">You are not the company presenting your business case. You are the journalist writing the investigative story about it five years after launch.</div>
    <ul class="cp-qs">
      <li class="cp-q"><span class="q-lbl">QUESTION 1</span>What is the headline of the story? What went wrong — and who was harmed?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 2</span>What did the company know, and when? Was there a point at which the harm was foreseeable?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
      <li class="cp-q"><span class="q-lbl">QUESTION 3</span>What one change to the design, governance structure, or deployment process would have prevented the story from being written?<textarea class="cp-input" placeholder="Write your response here..."></textarea></li>
    </ul>
    <div class="cp-note">Now go back to your actual business case and make that change — before it becomes the story.</div>
  </div>

  <div style="margin-top:40px">
    <span class="sec-label">The Executive Report Structure</span>
    <div class="report-sec"><span class="rep-wc">≈150 words</span><div class="rep-title">1 — Case Summary</div><div class="rep-desc">What did the company do, and what were the consequences? Factual and specific. No evaluative adjectives yet.</div><div class="rep-test">The test: could this section appear in a court document without being contested?</div></div>
    <div class="report-sec"><span class="rep-wc">≈300 words</span><div class="rep-title">2 — Ethical Analysis</div><div class="rep-desc">Apply Consequentialism plus at least one other framework. For each: state the core principle, apply it to specific facts, reach a verdict.</div><div class="rep-test">The test: if you removed the framework names, would two distinct analytical lenses still be clearly visible?</div></div>
    <div class="report-sec"><span class="rep-wc">≈150 words</span><div class="rep-title">3 — Accountability Chain</div><div class="rep-desc">Name each actor, their specific role in producing the harm, and the point at which they could have intervened.</div><div class="rep-test">The test: is every actor named a real decision-maker — or are you assigning responsibility to "the system"?</div></div>
    <div class="report-sec"><span class="rep-wc">≈200 words</span><div class="rep-title">4 — Connection to Your Business Case</div><div class="rep-desc">Name a specific risk, assumption, or design choice in your own case that the analysis has surfaced. State what you will do differently and why.</div><div class="rep-test">The test: if this section could apply to any business case, it is not specific enough.</div></div>
    <div class="dcallout red" style="margin-top:20px"><strong style="color:var(--red)">The common failure to avoid:</strong> Describing what a company automated rather than analysing why that automation was ethically significant. If your report could appear in the company's press release, it is description, not analysis.</div>
  </div>
</section>

<!-- ═══════════════════════════════════════════
     SECTION 6 — EXIT CHECK
═══════════════════════════════════════════ -->
<section id="s6" class="section-dark section">
  <span class="sec-label">Section 07 — Exit Check</span>
  <h2 class="sec-title" style="color:white">Can You Answer These?</h2>
  <p class="sec-intro">These are not revision questions. They are the minimum standard of analytical clarity expected before you write your executive report. If you cannot answer them without returning to the content — you are not ready to write.</p>

  <div class="exit-q">
    <div class="exit-n">01</div>
    <div class="exit-t">Why can a Consequentialist argument justify an action that a Deontologist would condemn — and which is the more appropriate lens for evaluating data collection without consent?</div>
    <div class="exit-h">Think about: the difference between evaluating outcomes versus evaluating the act itself.</div>
  </div>
  <div class="exit-q">
    <div class="exit-n">02</div>
    <div class="exit-t">When an AI system produces a discriminatory output and no human made the specific decision, who is accountable — and which ethical framework gives you the clearest answer?</div>
    <div class="exit-h">Consider: the data collector, the model designer, the deploying company, and the regulator each hold a piece of the accountability chain.</div>
  </div>
  <div class="exit-q">
    <div class="exit-n">03</div>
    <div class="exit-t">At what specific point in the AI development pipeline does algorithmic bias originate — and could it have been identified and corrected before deployment?</div>
    <div class="exit-h">Think about: data collection, labelling, training, testing, and deployment as distinct ethical checkpoints.</div>
  </div>
  <div class="exit-q">
    <div class="exit-n">04</div>
    <div class="exit-t">In your case, was the harm a predictable consequence of the design, or an unintended side effect of scaling — and does that distinction change the ethical verdict under a Virtue Ethics lens?</div>
    <div class="exit-h">A foreseeable harm is rarely excused by intent — but the character of the organisation behind the decision still matters.</div>
  </div>
  <div class="exit-q">
    <div class="exit-n">05</div>
    <div class="exit-t">What does the most ethically complex case from your group discussion reveal about the assumptions your own business case may be making — and which of those assumptions should you now challenge explicitly in your report?</div>
    <div class="exit-h">Comparative case analysis exists to illuminate your own blind spots — not just to evaluate other companies.</div>
  </div>

  <div class="final-commit">
    <div class="fc-lbl">CHECKPOINT 6.1 — FINAL: WRITE IT DOWN</div>
    <div class="fc-prompt">Before you close this site: write one sentence that states your position on the central ethical question of your business case. Not a description of the issue. A position — a claim you are prepared to defend using frameworks and evidence.</div>
    <textarea class="commit-input" id="commit-input" placeholder="My position is that..." oninput="checkCommit(this)"></textarea>
    <div id="commit-confirm">✓ That sentence is the beginning of your executive report.</div>
  </div>

  <div style="margin-top:80px;padding-top:40px;border-top:1px solid rgba(255,255,255,0.08);text-align:center">
    <div style="font-family:'Playfair Display',serif;font-size:13px;color:rgba(255,255,255,0.3);line-height:1.8">International Business Management · Module: Impact of New Technologies on Business &amp; Society<br>Ethical Implications of AI &amp; Machine Learning</div>
  </div>
</section>

</div><!-- end #main -->

<script>
// ── SIDEBAR TOGGLE ──────────────────────────────────────────
function toggleSidebar() {
  const sb = document.getElementById('sidebar');
  const main = document.getElementById('main');
  const toggle = document.getElementById('sb-toggle');
  const hidden = sb.classList.toggle('hidden');
  main.classList.toggle('full', hidden);
  toggle.classList.toggle('hidden', hidden);
  toggle.innerHTML = hidden ? '&#8250;' : '&#8249;';
}

// ── SCROLL TO ───────────────────────────────────────────────
function scrollTo(id) {
  document.getElementById(id).scrollIntoView({behavior:'smooth'});
}

// ── PROGRESS BAR + NAV HIGHLIGHT ────────────────────────────
const sectionIds = ['s0','s1a','s1b','s2','s3','s4','s5','s6'];
window.addEventListener('scroll', function() {
  const el = document.documentElement;
  const progress = el.scrollTop / (el.scrollHeight - el.clientHeight) * 100;
  document.getElementById('progress-fill').style.width = progress + '%';

  let active = sectionIds[0];
  sectionIds.forEach(id => {
    const section = document.getElementById(id);
    if (section && section.getBoundingClientRect().top <= 180) active = id;
  });
  document.querySelectorAll('.nav-item').forEach((item, i) => {
    item.classList.toggle('active', sectionIds[i] === active);
  });
});

// ── FRAMEWORK EXPLORER ──────────────────────────────────────
function showFw(id, btn) {
  document.querySelectorAll('.fw-panel').forEach(p => p.classList.remove('active'));
  document.getElementById('fw-' + id).classList.add('active');
  btn.closest('.fw-tabs').querySelectorAll('.fw-tab').forEach(b => b.classList.remove('active'));
  btn.classList.add('active');
}

// ── FRAMEWORK COMPARISON TOOL ───────────────────────────────
function showFcomp(id, btn) {
  ['c','d','v','r','f'].forEach(k => {
    const el = document.getElementById('fcomp-' + k);
    if (el) el.style.display = k === id ? 'block' : 'none';
  });
  btn.closest('.fcomp-tabs').querySelectorAll('.fw-tab').forEach(b => b.classList.remove('active'));
  btn.classList.add('active');
}

// ── SURVEILLANCE BUTTONS ────────────────────────────────────
function setSurv(btn, type) {
  const row = btn.closest('.surv-btns');
  row.querySelectorAll('.surv-btn').forEach(b => {
    b.classList.remove('ok','no','cond');
  });
  // toggle off if already selected
  if (!btn.classList.contains(type)) {
    btn.classList.add(type);
  }
}

// ── FINAL COMMITMENT ────────────────────────────────────────
function checkCommit(el) {
  const confirm = document.getElementById('commit-confirm');
  confirm.style.display = el.value.length > 20 ? 'block' : 'none';
}
</script>
</body>
</html>
